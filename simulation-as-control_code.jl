### A Pluto.jl notebook ###
# v0.19.8

#> [frontmatter]
#> author = "Andrew Ellis"
#> title = "Mental simulation as control"
#> date = "2022-06-16"

using Markdown
using InteractiveUtils

# This Pluto notebook uses @bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of @bind gives bound variables a default value (instead of an error).
macro bind(def, element)
    quote
        local iv = try Base.loaded_modules[Base.PkgId(Base.UUID("6e696c72-6542-2067-7265-42206c756150"), "AbstractPlutoDingetjes")].Bonds.initial_value catch; b -> missing; end
        local el = $(esc(element))
        global $(esc(def)) = Core.applicable(Base.get, el) ? Base.get(el) : iv(el)
        el
    end
end

# â•”â•â•¡ 1b9aeb61-3534-4363-8e27-e7c9df717480
using Distributions, PlutoUI, DataFrames

# â•”â•â•¡ 67d453be-1c76-4f2d-8660-76e5339f0953
using AlgebraOfGraphics, CairoMakie

# â•”â•â•¡ dfb8573e-0617-4636-b16b-7f1e0270b0bd
using Turing

# â•”â•â•¡ 45d7f55a-35de-47f6-9ce5-67fbbdeabaf3
using Base: @kwdef

# â•”â•â•¡ fde7f730-eca3-11ec-11fd-a3669efbfb62
md"# Simulation as a control problem"

# â•”â•â•¡ 9e4cf0fc-6654-4123-993e-39aa714b3731
md"""
It is commonly assumed that the brain's motor system makes use of internal models of the musculoskeletal system and the environment in order to control motor behaviour.

We will briefly discuss ideas originating in [Wolpert & Kawato (1998)](https://www.sciencedirect.com/science/article/pii/S0893608098000665) and explore their application to the mental simulation of behaviour.

> Humans exhibit an enormous repertoire of motor behavior which enables us to interact with many different objects under a variety of different environments.

Motor behavior is formulated as a control problem. In general, the problem of control can be considered as the computational process of determining the input to some system we wish to control ir order to achieve some desired output.

In essence, we can define _control_ as the attempt to make dynamical systems behave in a desirable way.

As an example, consider lifting a cup to ones lips. The desired output at time $t$ is a particular acceleration of the hand (as judged by proprioceptive sensory feedback). The input to the system must be a motor command.
"""

# â•”â•â•¡ 7b82b21f-dd19-4f6b-89a4-917f3c7ad770
md"""
Motor commands depend on many variables:
- (varying) state of the body (positions, velocities, orientation relative to gravity)
- (unvarying) masses, moments of inertia, etc.
- knowledge of interactions with outside world (e.g. geometry and properties of cup)

All these (and more) can be considered as the context $C$ within which movement takes place. Motor commands must be tailored to take into account the current context.
"""

# â•”â•â•¡ 45cd5b3a-0a3d-4e80-8cc1-33b734016ad6
md"""
## Forward and inverse models

The notion of an internal model, a system which mimics the behavior of a natural process, has emerged as an important theoretical concept in motor control.

There are two varieties of internal model, forward and inverse models. 

Forward models capture the forward or causal relationship between inputs to the system, e.g. the arm, and the outputs (Ito, 1970; Kawato et al., 1987; Jordan, 1995). A forward dynamic model of the arm, for example predicts the next state (e.g. position and velocity) given the current state and motor command.

In contrast, inverse models invert the system by providing the motor command which will cause a desired change in state. Inverse models are, therefore, well suited to act as controllers as they can provide the motor command necessary to achieve some desired state transition.

As both forward and inverse models depend on the dynamics of the motor system, which _change throughout life and under different contextual conditions, these models must be adaptable_.

## Multiple models

Wolpert & Kawato (1998) claim that there is evidence for the existence of multiple (independent) controllers (as opposed to one monolithic controller). The problem of choosing which model is responsible for actually controlling behaviour can be seen as a model selection problem.

__Assumptions__: At any given time, only certain controllers are active. Only the active controllers can be assessed for performance errors. 

The basic idea of Wolpert & Kawato's model is that multiple inverse models exist to control the system and each is augmented with a corresponding forward model. The brain therefore contains multiple pairs of coupled forward and inverse models. Further, there exists a _responsibility signal_ (for a given model) which reflects, at any given time, the degree to which each pair of forward and inverse models should be responsible for controlling the current behavior. This responsibility signal is derived from the combination of two processes. The first process uses the forward modelâ€™s predictions errors. The second process, the responsibility predictors, use sensory contextual cues to predict the responsibility of the module and can therefore select controllers prior to movement initiation in a feedforward manner.

> I don't know yet if it's worth exploring their model in great detail.




## Forward and inverse models as inference

In a more modern take, forward and inverse models can be interpreted as two types of inference in a probabilistic model. 

This will allow us to deal with uncertainty.
"""

# â•”â•â•¡ 96f3de55-017f-4497-a9ee-0842c1e4a600
md"""
## Model

We consider an agent's motor system, which we wish to control by issuing a sequence of motor commands $u_{1...T}$. For simplicity, we consider discrete time. 

The resulting movement trajectory (state of the system) is $x_{1...T}$. 


The causal relationship between motor command $u$ and state $x$ is given by:

$x_{t+1} = f(x_t, u_t, c_t)$

This describes the _forward_ dynamics of the system. We assume that the dynamics of the system $f$ are not fixed over time but can take on a possibly infinite number of different forms. These different forms correspond to the context of the movement and include such factors as interactions with objects or changes in the environment. This can either be parameterized by assuming there is a set of system dynamics $f_i$ with $i = 1, 2, ..., n$ or by including a context parameter $c$ as part of the dynamics.

The aim of control is to produce a system which can generate an appropriate motor command $u_t$ given the desired state, $x_{t+1}^\ast$.
"""

# â•”â•â•¡ 54513b17-f40a-4948-abfa-ff13e5fdc48b
md"""
## Simulations
"""

# â•”â•â•¡ 147b95f9-903e-440e-92a4-f59a9f5897e8
md"""
Let's consider a simple agent that can move (change its position) along a unidimensional axis. We will denote the position at time $t$ by $Î¸_t$.
"""

# â•”â•â•¡ bd29c3c5-8678-493c-b7ca-1209461d9941
PlutoUI.LocalResource("assets/bear-with-phone.png")

# â•”â•â•¡ f29282a5-8f30-4759-9481-cf1153b91262
md"""
The agent is equipped with a GPS device, with which it can measure its position along the axis. However, the measurements are noisy, such that the observation a time $t$ is given by:

$$y_t \sim \mathcal{N}(\theta_{t}, \sigma^2_y)$$
"""

# â•”â•â•¡ 93b6a338-4222-4f1c-a61f-4ae3c53a3569
md"""
The agent can move (left/right) by applying a force. Neglecting pretty much everything else (mass, friction, etc.), the applied force results in a single cycle sinusiodal acceleration. 

Therefore, the agent's motor action will result in an acceleration. We know that acceleration, $\alpha$, is the second derivative of position. We can therefore numerically integrate (twice) the acceleration over a time period to obtain the velocity, $\omega$, and then the position.

$$\begin{align}
\omega_t &=  \dot{Î¸}_t\\
\alpha_t &= \dot{\omega}_t = \ddot{\theta}_t = u_t\\
r_{t+1} &= r_t + c \, i_t
\end{align}$$
"""

# â•”â•â•¡ 51799b48-ab66-49f6-b675-11d2f556f1b2
md"""

Using this information, we can write the agent's motion as a system of 1st order difference equations. These implement Newtonian kinematics.

$$\begin{align}
 u_t &= \alpha_t \\
\alpha_t &= D \cdot A  \cdot sin(2 * Ï€ * f * (t-\phi)) \\
\omega_{t+1} &= \omega_{t} + \Delta t \cdot \alpha_t \\
\theta_{t+1} &= \theta_{t} + \Delta t \cdot \omega_{t} + \frac{1}{2} \Delta t ^2 \cdot \alpha_t \\

\end{align}$$

where $D$, $A$, $\phi$ are the direction (sign), amplitude and phase, i.e. parameters of the sinusiodal acceleration. 
"""

# â•”â•â•¡ db19811e-6680-4c7e-98d8-652b4d35214a
md"""
Let's try this out using a code example. You can use the sliders to set the amplitude, direction, onset and duration of motion.
"""

# â•”â•â•¡ 6d343fb0-0eb5-43e7-ae6b-34c62a7da084
amplitude = @bind amplitude PlutoUI.Slider(0:20, default = 10)

# â•”â•â•¡ 50159681-0c1c-4961-8318-d84ab7e95fce
direction = @bind direction Select(["left", "right"])

# â•”â•â•¡ 43165e68-2265-4bf9-8f19-0dea04f29cfb
duration = @bind duration PlutoUI.Slider(0.5:6, default = 2)

# â•”â•â•¡ f6fc7de8-db7b-4861-b045-b385f2ad97d5
onset = @bind onset PlutoUI.Slider(0:2, default = 1)

# â•”â•â•¡ 46a0daaa-ace4-4ecb-8ff1-09a88b634a1c
md"""
Now we can simulate the result of applying an acceleration with the parameters defined above, and plot the resulting velocity, position and sensory observations.
"""

# â•”â•â•¡ 2983a87e-7c52-447a-bbeb-3baeed09e611
show_observations = @bind show_observations CheckBox()

# â•”â•â•¡ a7e2c25e-7b06-41a9-903f-65396ca1c09e
md"""
## Control 

What we did above was use the model to perform a forward simulation of the expected consequences of applying a motor command. The problem of controlling, i.e. selecting an appropriate action, is the inverse problem: in this case, figuring out which parameter settings to use in order to achieve a desired target position.

Say, for example, that the agent wishes to go to position $\theta = 10$. For simplicity, let's assume that the agent doens't care how long it takes to get there.


The problem can be construed in serveral ways. I propose that we either look at it as an optimization problem, or as a problem of Bayesian inference.
"""

# â•”â•â•¡ 37079a26-df04-4de9-b2b2-4f2504a21ba7
md"""
### Control as optimization

"""

# â•”â•â•¡ c6b44155-bd04-45dd-bba6-9b85a79d2487
md"""tbd..."""

# â•”â•â•¡ ec74d6c2-e223-41cd-b1f7-3e6a6945d829
md"""
### Control as inference

The goal is to infer a posterior distribution over the parameters, conditioned upon setting $\theta = 10$. The parameters of interest are the duration and apmplitude; the direction of motion is given by the target position, since we are not (yet) considering circular motion.

The agent has to perform the following steps:
1) Set up probabilistic model.
2) Infer parameters, conditioned upon setting position to the desired value.
"""

# â•”â•â•¡ 73a771b4-ad0f-4c64-bfb7-38aba7dc90f2
md"""
To be continued...
"""

# â•”â•â•¡ b1161fc7-7779-44ec-a570-b335b3ba9745
md"""
## Code

"""

# â•”â•â•¡ 10e1593e-0216-45e6-9c36-206e54848f67
begin

	@kwdef struct Sensor
    noise::Distribution = Normal(0, 1.0)
	end

	@kwdef struct PlannedMovement
    A::Real = 20 # amplitude
    D::String = "right" # direction
    onset::Real = 1
    duration::Real = 1
	end
	
	function acceleration(D::Number, A::Number, 
		f::Number, t::Number, start::Number)
		D * A * sin.(2 * Ï€ * f * (t-start))
	end
	
end

# â•”â•â•¡ 57bea528-1106-4935-bfd3-c96426b39e15
mu = PlannedMovement(A=amplitude, D=direction, onset=onset, duration=duration);

# â•”â•â•¡ 88b40a8d-900b-40c2-be5d-5fb32923919b
mu

# â•”â•â•¡ 9ea6db4d-8859-4bb3-86eb-b16d91178dec
sensor = Sensor(noise=Normal(0, 1.0));

# â•”â•â•¡ 832c29eb-49b1-41d4-98e7-960fb30ed9a1
begin
	function simulate(máµ¤::PlannedMovement, sensor::Sensor; Î”t = 0.01, duration::Real = 2)
		
    onsetáµ¤ = máµ¤.onset
    @assert onsetáµ¤ >= 0
    @assert duration > 0

    motion_duration = máµ¤.duration
    total_duration = duration

    onsetáµ¤ +  motion_duration <= total_duration || error("Head turn extends beyond simulation event.")

    máµ¤.D âˆˆ ["left", "right"] || error("Direction not specified.")

    D = máµ¤.D == "left" ? -1 : 1
    A =máµ¤.A 

    noise = sensor.noise
    f = 1/(motion_duration) # frequency: single cycle sinusoidal 

    timesteps = range(0, stop = total_duration, step = Î”t)
    T = length(timesteps)

    Î± = zeros(T)
    Ï‰ = zeros(T)
    Î¸ = zeros(T)
    y = zeros(T)

    for i âˆˆ Iterators.drop(1:T, 1)
        t = round(timesteps[i]; digits = 3)
        Î±[i] = (t > onsetáµ¤) & (t < onsetáµ¤ + motion_duration) ? acceleration(D, A, f, t, onsetáµ¤) : 0
        Ï‰[i] = Ï‰[i-1] + Î”t * Î±[i]
        Î¸[i] = Î¸[i-1] + Î”t * Ï‰[i] + 1/2 * Î”t^2 * Î±[i]
        y[i] = Î¸[i] + rand(noise)
    end
    
    out = (timesteps = collect(timesteps),
            y = y,
            Î± = Î±, 
            Ï‰ = Ï‰, 
            Î¸ = Î¸, 
            Î”t = Î”t, onsetáµ¤ = onsetáµ¤,
            sensor = noise, 
            máµ¤ = máµ¤)
    return out

end
end

# â•”â•â•¡ bb7be262-3487-4130-ab9c-8d1d46c51c3f
s = simulate(mu, sensor, Î”t=0.01, duration=onset+duration+2);

# â•”â•â•¡ 60af8174-7968-458f-9028-c2b80697e60c
@model function infer_motion(y, N; u, ÏƒÏ‰, ÏƒÎ¸, Ïƒy, Î”t)
    Ï‰ = tzeros(Real, N)
	Î¸ = tzeros(Real, N)

    Ï‰[1] ~ Normal(0, ÏƒÏ‰)
	Î¸[1] ~ Normal(0, ÏƒÎ¸)
    y[1] ~ Normal(Î¸[1], Ïƒy)

    for i âˆˆ 2:N
        Ï‰[i] ~ Normal(Ï‰[i-1] + Î”t * u[i], ÏƒÏ‰)
        # Î¸[i] ~ Normal(Î¸[i-1] + Î”t * Ï‰[i-1] + 0.5 * Î”t^2 * u[i], ÏƒÎ¸)
		Î¸[i] = Î¸[i-1] + Î”t * Ï‰[i-1] + 0.5 * Î”t^2 * u[i]
        y[i] ~ Normal(Î¸[i], Ïƒy)
    end
	return Î¸
end

# â•”â•â•¡ 50fe5674-cbde-4443-b3d9-4cc42beb59dd
begin 
	N = length(s.y)
    D = s.máµ¤.D == "left" ? -1 : 1
	
	ÏƒÏ‰ = 0.05
	ÏƒÎ¸ = 0.05
	
    timesteps = range(0, stop=N * s.Î”t, step=s.Î”t)
    f = 1 / (duration)
    u = zeros(N)
    for i âˆˆ 2:N
        t = timesteps[i]
        u[i] = (t >= s.máµ¤.onset) && (t <= s.máµ¤.onset + s.máµ¤.duration) ? acceleration(D, s.máµ¤.A, f, t, s.máµ¤.onset) : 0.0
    end
	
	forward_model = infer_motion(s.y, N, u=u, ÏƒÏ‰=ÏƒÏ‰, ÏƒÎ¸=ÏƒÎ¸, Ïƒy=s.sensor.Ïƒ, Î”t=s.Î”t)	
	posterior = sample(forward_model, SMC(), 1000);
end

# â•”â•â•¡ f7a342a5-b19e-456f-9d61-cc372fc1c51b
begin
    # chains_params = Turing.MCMCChains.get_sections(posterior, :Î¸)
    gen = generated_quantities(forward_model, posterior)
end

# â•”â•â•¡ a3dcdc7d-4298-458f-ab7c-5a3ee55dd7fd
begin
	using Query
	d = DataFrame(group(posterior, :Î¸))
	select!(d, Not(:chain))
	colnames = vcat(:iteration, ["$i" for i in 1:ncol(d)-1])
	rename!(d, Symbol.(colnames))

	nsamples = 100
	dd = d[sample(axes(d, 1), nsamples; replace=false, ordered=true), :]

	dd = DataFrames.stack(dd, Not([:iteration]),
    	variable_name=:time, value_name=:Î¸)

	dd = dd |>
    @mutate(time = parse(Int64, _.time),
            iteration = string.(_.iteration)) |>
    @mutate(time = _.time*s.Î”t) |> DataFrame
end

# â•”â•â•¡ bb226991-1eec-44f1-a4eb-dbcd9126e6e7
@model function inferparams(y, Î¸_desired, N; u, ÏƒÏ‰, ÏƒÎ¸, Ïƒy, Î”t)
    Ï‰ = tzeros(Real, N)
	Î¸ = tzeros(Real, N)

    Ï‰[1] ~ Normal(0, ÏƒÏ‰)
	Î¸[1] ~ Normal(0, ÏƒÎ¸)
    y[1] ~ Normal(Î¸[1], Ïƒy)

    for i âˆˆ 2:N
        Ï‰[i] ~ Normal(Ï‰[i-1] + Î”t * u[i], ÏƒÏ‰)
        Î¸[i] = Normal(Î¸[i-1] + Î”t * Ï‰[i-1] + 0.5 * Î”t^2 * u[i], ÏƒÎ¸)
        y[i] ~ Normal(Î¸[i], Ïƒy)
    end
end

# â•”â•â•¡ 324042ac-79cb-46a0-af2f-8db16e6bf717
begin
	function get_estimates(chain::Chains, var::Symbol)
    	x = Array(group(chain, var))
    	return (var=x)
	end
end

# â•”â•â•¡ 3c0cc555-3670-4ce5-a6b8-bea14cbc06fc
Î¸ = get_estimates(posterior, :Î¸);

# â•”â•â•¡ df45ae13-8625-40fc-9520-322a47eb4855
Ï‰ = get_estimates(posterior, :Ï‰);

# â•”â•â•¡ 17d59070-ab0e-4c96-97d0-26a000723ec9
begin
	q025(x) = quantile(x, 0.025)
	q975(x) = quantile(x, 0.97)
	
	function compute_stats(x::Array)
    mean_x = mean.(eachslice(x, dims=2))
    xlb = mean_x .- q025.(eachslice(x, dims=2))
    xub = mean_x .- q975.(eachslice(x, dims=2))
    return (Î¼=mean_x, lb=xlb, ub=xub)
	end
end

# â•”â•â•¡ 2bf1a8ef-16f0-4da7-9766-e58455df7e83
begin
	plt = data(dd) *
		visual(Lines, color = :steelblue3, linewidth = 0.2, alpha = 0.1) *
     	mapping(:time, :Î¸, group=:iteration)
	
	fig2 = draw(plt)
	
	Î¼Î¸, lbÎ¸, ubÎ¸ = compute_stats(Î¸)
	lines!(s.timesteps, Î¼Î¸, 
        linewidth=2,
        linestyle = :dash,
        color=:steelblue3)
	current_figure()
end

# â•”â•â•¡ 9a641cd1-f031-4dc9-837f-e9e69a13566d
md"""

## References

Wolpert, D. M., & Kawato, M. (1998). Multiple paired forward and inverse models for motor control. Neural Networks, 11(7), 1317â€“1329. [https://doi.org/10.1016/S0893-6080(98)00066-5](https://www.sciencedirect.com/science/article/pii/S0893608098000665)

"""

# â•”â•â•¡ 2c12b0de-ed33-44b0-88d8-3f3195eb9e98
html"""<style>
main {
    max-width: 100%;
}
"""

# â•”â•â•¡ 590e843d-5881-4e41-aab8-3c4ef6bc83bc
TableOfContents(title="ğŸ“š Table of Contents", 
	indent=true, depth=4, aside=true)

# â•”â•â•¡ 2ee44f38-df4c-4109-b099-eb159fc0d0fa
begin
	publication_theme() = Theme(
		fontsize=18, font="sans",
		Axis=(xlabelsize=20, xgridstyle=:dash, ygridstyle=:dash,
        xtickalign=1, ytickalign=1, yticksize=10, xticksize=10,
        xlabelpadding=-5, ylim=(0, 5)), 
		Legend=(framecolor=(:black, 0.5), 
		bgcolor=(:white, 0.5)),
		Colorbar=(ticksize=16, tickalign=1, spinewidth=0.5))
end

# â•”â•â•¡ b0adc44e-8e3f-4f9e-b183-c943fd122c69
begin
	with_theme(publication_theme()) do
    f1 = lines(s.timesteps, s.Î±,
        linewidth=3,
        color=:black,
		linestyle=:solid,
		label = "Acceleration",
        axis=(xticks=LinearTicks(6),
            xlabel="Time (s)",
            ylabel="Position (arbitrary units)",
            xgridstyle=:dash, ygridstyle=:dash))
	f2 = lines!(s.timesteps, s.Ï‰,
        linewidth=6,
        color=:darkorange,
	label = "Velocity")	
	f3 = lines!(s.timesteps, s.Î¸,
        linewidth=6,
        color=:steelblue3,
	    linestyle=:solid,
	label = "Position")	
	f4 = show_observations && scatter!(s.timesteps, s.y,
	        color=(:steelblue3),
			marker='â—†',
        	markersize=6,
	label = "Observations")
	vspan!([0, mu.onset + mu.duration], [mu.onset, maximum(s.timesteps)],color = [(c, 0.2) for c in [:grey, :grey]])
    ylims!(min(minimum(s.Î±), minimum(s.Î¸)) - 1, max(maximum(s.Î±), maximum(s.Î¸)) + 1)
	axislegend(position = :rb, orientation = :horizontal)
    current_figure()
end
end

# â•”â•â•¡ 02d3cd9d-3c53-49e2-882c-056f3225bb27
begin
	fig1 = with_theme(publication_theme()) do
    Î¼Î¸, lbÎ¸, ubÎ¸ = compute_stats(Î¸)
    Î¼Ï‰, lbÏ‰, ubÏ‰ = compute_stats(Ï‰)

    lines(s.timesteps, Î¼Ï‰,
        linewidth=4,
        color="darkorange",
        axis=(xticks=LinearTicks(6),
            xlabel="Time (s)",
            ylabel="Inferred position/velocity",
            xgridstyle=:dash, ygridstyle=:dash))
    lines!(s.timesteps, Î¼Î¸,
        linewidth=4,
        color=:steelblue3)
    band!(s.timesteps, Î¼Ï‰ - lbÏ‰, Î¼Ï‰ - ubÏ‰, color=(:darkorange, 0.5))
    band!(s.timesteps, Î¼Î¸ - lbÎ¸, Î¼Î¸ - ubÎ¸, color=(:steelblue3, 0.5))
    lines!(s.timesteps, s.Î¸, linewidth=4, linestyle=:dash, color=:black)
    current_figure()
end

end

# â•”â•â•¡ a83e98d0-1275-437e-947d-d14613432253
note(text) = Markdown.MD(Markdown.Admonition("note", "Note", [text]))

# â•”â•â•¡ d9f6f38e-0a10-411e-abf7-64fc75277963
note(md"""
The agent's observations are of course a model of a sensory system. We are assuming that the sensor noise is homoscedastic.""")

# â•”â•â•¡ d62199a4-c460-484f-9793-b49af77b15bb
note(md"""
We are assuming that the agent can only perform one type of motion (sinusiodal acceleration), and has perfect knowledge of the form of the acceleration. Further, the acceleration is parameterized using $D$, $A$, $\phi$. $f$ is set to $1$ because the agent's motor system can only perform a single cycle pf motion.
""")

# â•”â•â•¡ Cell order:
# â• â•1b9aeb61-3534-4363-8e27-e7c9df717480
# â• â•67d453be-1c76-4f2d-8660-76e5339f0953
# â• â•dfb8573e-0617-4636-b16b-7f1e0270b0bd
# â• â•45d7f55a-35de-47f6-9ce5-67fbbdeabaf3
# â•Ÿâ”€fde7f730-eca3-11ec-11fd-a3669efbfb62
# â•Ÿâ”€9e4cf0fc-6654-4123-993e-39aa714b3731
# â•Ÿâ”€7b82b21f-dd19-4f6b-89a4-917f3c7ad770
# â•Ÿâ”€45cd5b3a-0a3d-4e80-8cc1-33b734016ad6
# â•Ÿâ”€96f3de55-017f-4497-a9ee-0842c1e4a600
# â•Ÿâ”€54513b17-f40a-4948-abfa-ff13e5fdc48b
# â•Ÿâ”€147b95f9-903e-440e-92a4-f59a9f5897e8
# â•Ÿâ”€bd29c3c5-8678-493c-b7ca-1209461d9941
# â•Ÿâ”€f29282a5-8f30-4759-9481-cf1153b91262
# â•Ÿâ”€d9f6f38e-0a10-411e-abf7-64fc75277963
# â•Ÿâ”€93b6a338-4222-4f1c-a61f-4ae3c53a3569
# â•Ÿâ”€51799b48-ab66-49f6-b675-11d2f556f1b2
# â•Ÿâ”€d62199a4-c460-484f-9793-b49af77b15bb
# â•Ÿâ”€db19811e-6680-4c7e-98d8-652b4d35214a
# â• â•6d343fb0-0eb5-43e7-ae6b-34c62a7da084
# â•Ÿâ”€50159681-0c1c-4961-8318-d84ab7e95fce
# â•Ÿâ”€43165e68-2265-4bf9-8f19-0dea04f29cfb
# â•Ÿâ”€f6fc7de8-db7b-4861-b045-b385f2ad97d5
# â•Ÿâ”€46a0daaa-ace4-4ecb-8ff1-09a88b634a1c
# â• â•57bea528-1106-4935-bfd3-c96426b39e15
# â• â•9ea6db4d-8859-4bb3-86eb-b16d91178dec
# â• â•bb7be262-3487-4130-ab9c-8d1d46c51c3f
# â•Ÿâ”€2983a87e-7c52-447a-bbeb-3baeed09e611
# â•Ÿâ”€b0adc44e-8e3f-4f9e-b183-c943fd122c69
# â•Ÿâ”€a7e2c25e-7b06-41a9-903f-65396ca1c09e
# â•Ÿâ”€37079a26-df04-4de9-b2b2-4f2504a21ba7
# â•Ÿâ”€c6b44155-bd04-45dd-bba6-9b85a79d2487
# â•Ÿâ”€ec74d6c2-e223-41cd-b1f7-3e6a6945d829
# â•Ÿâ”€73a771b4-ad0f-4c64-bfb7-38aba7dc90f2
# â• â•88b40a8d-900b-40c2-be5d-5fb32923919b
# â• â•50fe5674-cbde-4443-b3d9-4cc42beb59dd
# â• â•3c0cc555-3670-4ce5-a6b8-bea14cbc06fc
# â• â•df45ae13-8625-40fc-9520-322a47eb4855
# â• â•f7a342a5-b19e-456f-9d61-cc372fc1c51b
# â• â•02d3cd9d-3c53-49e2-882c-056f3225bb27
# â• â•a3dcdc7d-4298-458f-ab7c-5a3ee55dd7fd
# â• â•2bf1a8ef-16f0-4da7-9766-e58455df7e83
# â•Ÿâ”€b1161fc7-7779-44ec-a570-b335b3ba9745
# â• â•10e1593e-0216-45e6-9c36-206e54848f67
# â• â•832c29eb-49b1-41d4-98e7-960fb30ed9a1
# â• â•60af8174-7968-458f-9028-c2b80697e60c
# â• â•bb226991-1eec-44f1-a4eb-dbcd9126e6e7
# â• â•324042ac-79cb-46a0-af2f-8db16e6bf717
# â• â•17d59070-ab0e-4c96-97d0-26a000723ec9
# â•Ÿâ”€9a641cd1-f031-4dc9-837f-e9e69a13566d
# â• â•2c12b0de-ed33-44b0-88d8-3f3195eb9e98
# â• â•590e843d-5881-4e41-aab8-3c4ef6bc83bc
# â• â•2ee44f38-df4c-4109-b099-eb159fc0d0fa
# â• â•a83e98d0-1275-437e-947d-d14613432253
